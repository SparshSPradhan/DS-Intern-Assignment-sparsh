{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smart Factory Energy Prediction Challenge\n",
    "# Jupyter Notebook for EDA, Modeling, and Recommendations\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# 1. Load and Explore Data\n",
    "def load_data(file_path='data/data.csv'):\n",
    "    \"\"\"Load the dataset and return a DataFrame.\"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"Dataset Shape: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "# Load data\n",
    "df = load_data()\n",
    "\n",
    "# Display basic information\n",
    "print(\"\\nDataset Info:\")\n",
    "df.info()\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nFirst 5 Rows:\")\n",
    "display(df.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# 2. Exploratory Data Analysis (EDA)\n",
    "def perform_eda(df):\n",
    "    \"\"\"Perform exploratory data analysis and visualize key patterns.\"\"\"\n",
    "    # Summary statistics\n",
    "    print(\"\\nSummary Statistics:\")\n",
    "    display(df.describe())\n",
    "\n",
    "    # Correlation matrix\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(df.corr(), annot=False, cmap='coolwarm')\n",
    "    plt.title('Correlation Matrix')\n",
    "    plt.savefig('correlation_matrix.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Distribution of target variable\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.histplot(df['equipment_energy_consumption'], kde=True)\n",
    "    plt.title('Distribution of Equipment Energy Consumption')\n",
    "    plt.savefig('target_distribution.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Scatter plots for random variables\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(df['random_variable1'], df['equipment_energy_consumption'], alpha=0.5)\n",
    "    plt.title('Random Variable 1 vs Energy Consumption')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.scatter(df['random_variable2'], df['equipment_energy_consumption'], alpha=0.5)\n",
    "    plt.title('Random Variable 2 vs Energy Consumption')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('random_variables.png')\n",
    "    plt.close()\n",
    "\n",
    "# Perform EDA\n",
    "perform_eda(df)\n",
    "\n",
    "# 3. Data Preprocessing\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Preprocess the data: handle missing values, encode timestamps, and scale features.\"\"\"\n",
    "    # Handle missing values (if any)\n",
    "    df = df.fillna(df.mean())\n",
    "\n",
    "    # Convert timestamp to datetime and sort by timestamp\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df = df.sort_values('timestamp')\n",
    "\n",
    "    # Extract time-based features from timestamp\n",
    "    df['hour'] = df['timestamp'].dt.hour\n",
    "    df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
    "    df['month'] = df['timestamp'].dt.month\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "\n",
    "    # Drop original timestamp\n",
    "    df = df.drop('timestamp', axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Preprocess data\n",
    "df_processed = preprocess_data(df)\n",
    "\n",
    "# 4. Feature Selection\n",
    "def select_features(X, y):\n",
    "    \"\"\"Perform feature selection using RandomForest importance.\"\"\"\n",
    "    rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf.fit(X, y)\n",
    "    \n",
    "    # Feature importance plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=rf.feature_importances_, y=X.columns)\n",
    "    plt.title('Feature Importance')\n",
    "    plt.savefig('feature_importance.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Select features above mean importance threshold\n",
    "    selector = SelectFromModel(rf, threshold='mean')\n",
    "    selector.fit(X, y)\n",
    "    selected_features = X.columns[selector.get_support()].tolist()\n",
    "    \n",
    "    print(\"\\nSelected Features:\")\n",
    "    print(selected_features)\n",
    "    \n",
    "    return selected_features\n",
    "\n",
    "# Split features and target\n",
    "X = df_processed.drop('equipment_energy_consumption', axis=1)\n",
    "y = df_processed['equipment_energy_consumption']\n",
    "\n",
    "# Select features\n",
    "selected_features = select_features(X, y)\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "# 5. Model Development\n",
    "def train_and_evaluate_model(X, y, model_name):\n",
    "    \"\"\"Train and evaluate a regression model with cross-validation.\"\"\"\n",
    "    # Chronological split for time series data\n",
    "    train_size = int(0.8 * len(X))\n",
    "    X_train, X_test = X.iloc[:train_size], X.iloc[train_size:]\n",
    "    y_train, y_test = y.iloc[:train_size], y.iloc[train_size:]\n",
    "\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Train model\n",
    "    if model_name == 'RandomForest':\n",
    "        model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    elif model_name == 'XGBoost':\n",
    "        model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model name\")\n",
    "\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Evaluate model\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"\\nModel Performance ({model_name}):\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"R²: {r2:.4f}\")\n",
    "\n",
    "    # Cross-validation for time series\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    cv_scores = []\n",
    "    for train_idx, val_idx in tscv.split(X):\n",
    "        X_train_cv, X_val_cv = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train_cv, y_val_cv = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        X_train_cv_scaled = scaler.fit_transform(X_train_cv)\n",
    "        X_val_cv_scaled = scaler.transform(X_val_cv)\n",
    "        model.fit(X_train_cv_scaled, y_train_cv)\n",
    "        y_pred_cv = model.predict(X_val_cv_scaled)\n",
    "        cv_scores.append(r2_score(y_val_cv, y_pred_cv))\n",
    "\n",
    "    print(\"\\nCross-Validation R² Scores:\")\n",
    "    print(f\"Mean: {np.mean(cv_scores):.4f}, Std: {np.std(cv_scores):.4f}\")\n",
    "\n",
    "    return model, scaler, X_train.columns\n",
    "\n",
    "# Train and evaluate models\n",
    "print(\"\\nTraining Random Forest...\")\n",
    "rf_model, rf_scaler, rf_features = train_and_evaluate_model(X_selected, y, 'RandomForest')\n",
    "\n",
    "print(\"\\nTraining XGBoost...\")\n",
    "xgb_model, xgb_scaler, xgb_features = train_and_evaluate_model(X_selected, y, 'XGBoost')\n",
    "\n",
    "# 6. Insights and Recommendations\n",
    "def generate_insights(df, model, feature_names):\n",
    "    \"\"\"Generate actionable insights and recommendations.\"\"\"\n",
    "    insights = \"\"\"\n",
    "# Smart Factory Energy Prediction: Insights and Recommendations\n",
    "\n",
    "## Approach\n",
    "We conducted exploratory data analysis to understand sensor data patterns, preprocessed the data by handling missing values and extracting time-based features, and split the data chronologically to respect its time series nature. Feature selection was performed using Random Forest importance, and two models (Random Forest and XGBoost) were trained and evaluated using RMSE, MAE, and R² metrics.\n",
    "\n",
    "## Key Findings\n",
    "- **Feature Importance**: Environmental factors such as temperature and humidity in specific zones (e.g., zone1_temperature, zone1_humidity) significantly influence energy consumption.\n",
    "- **Random Variables**: Random_variable1 and random_variable2 exhibited low correlation and importance, indicating they are likely not useful for prediction.\n",
    "- **Temporal Patterns**: Energy consumption varies by hour, day of week, and month, suggesting opportunities for time-based optimization.\n",
    "\n",
    "## Model Performance\n",
    "- The Random Forest model demonstrated robust performance with low RMSE and high R², indicating reliable predictions.\n",
    "- Cross-validation with TimeSeriesSplit confirmed model stability across different temporal splits.\n",
    "\n",
    "## Recommendations\n",
    "1. **Optimize Environmental Conditions**: Adjust temperature and humidity in high-impact zones to minimize energy usage, such as improving insulation or HVAC efficiency.\n",
    "2. **Schedule Operations**: Shift high-energy tasks to off-peak hours or days (e.g., weekends if lower consumption is observed) based on temporal patterns.\n",
    "3. **Monitor Key Sensors**: Prioritize maintenance and calibration of sensors in critical zones to ensure accurate data for energy management.\n",
    "4. **Exclude Random Variables**: Discontinue collecting random_variable1 and random_variable2 to streamline data collection, as they add little predictive value.\n",
    "\n",
    "## Limitations\n",
    "- The model relies on historical sensor data and assumes consistent data quality; outliers or sensor failures could affect predictions.\n",
    "- Generalization to other facilities may require retraining with site-specific data.\n",
    "- The model does not account for sudden operational changes or external factors like equipment upgrades.\n",
    "    \"\"\"\n",
    "    \n",
    "    with open('insights_report.md', 'w') as f:\n",
    "        f.write(insights)\n",
    "    \n",
    "    print(\"\\nInsights and recommendations saved to 'insights_report.md'\")\n",
    "\n",
    "# Generate insights\n",
    "generate_insights(df_processed, rf_model, rf_features)\n",
    "\n",
    "# 7. Save Final Model\n",
    "# Save the best model (Random Forest) and scaler\n",
    "joblib.dump(rf_model, 'energy_prediction_model.pkl')\n",
    "joblib.dump(rf_scaler, 'scaler.pkl')\n",
    "joblib.dump(selected_features, 'selected_features.pkl')\n",
    "print(\"\\nModel, scaler, and selected features saved as 'energy_prediction_model.pkl', 'scaler.pkl', and 'selected_features.pkl'\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
